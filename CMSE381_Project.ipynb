{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSE 381 Final Project Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTRUCTIONS**: This is a template to help organize your project.  All projects should include the 5 major sections below (you do not need to use this template file).  If you use this file, complete your work below and remove content in parentheses. Also, remove this current cell.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CMSE 381 Final Project\n",
    "### &#9989; Group members: Mehrshad, Rithvik\n",
    "### &#9989; Section_002\n",
    "#### &#9989; 11/29/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___PROJECT TITLE HERE___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Provide context for the problem.  **Clearly state the question(s) you set\n",
    "out to answer.**)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "_(How did you go about answering your question(s)? You should wrote some code here to demonstrate what the data is like and how in principle your method works. You can leave the variations of the related to specific results to the results section.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CSV files found: 193\n",
      "First 5 file names:\n",
      "   Freiwald_Tsao_faceviews_AM_data_csv/raster_data_bert_am_site070.csv\n",
      "   Freiwald_Tsao_faceviews_AM_data_csv/raster_data_lupo_am_site181.csv\n",
      "   Freiwald_Tsao_faceviews_AM_data_csv/raster_data_bert_am_site138.csv\n",
      "   Freiwald_Tsao_faceviews_AM_data_csv/raster_data_bert_am_site110.csv\n",
      "   Freiwald_Tsao_faceviews_AM_data_csv/raster_data_bert_am_site105.csv\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# Import modules and find all CSV files\n",
    "# ------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Path to folder containing the 193 CSV files\n",
    "data_path = \"Freiwald_Tsao_faceviews_AM_data_csv\"\n",
    "\n",
    "# list of all CSV files in that folder\n",
    "csv_files = glob.glob(os.path.join(data_path, \"*.csv\"))\n",
    "\n",
    "print(\"Number of CSV files found:\", len(csv_files))\n",
    "print(\"First 5 file names:\")\n",
    "for f in csv_files[:5]:\n",
    "    print(\"  \", f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Data\n",
    "_(Describe the data you are using. What variables are you using? What they mean? Why did you choose them?)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 files with the most trials:\n",
      "Freiwald_Tsao_faceviews_AM_data_csv/raster_data_bert_am_site185.csv  -->  2685 trials\n",
      "Freiwald_Tsao_faceviews_AM_data_csv/raster_data_bert_am_site186.csv  -->  2685 trials\n",
      "Freiwald_Tsao_faceviews_AM_data_csv/raster_data_bert_am_site265.csv  -->  2431 trials\n",
      "Freiwald_Tsao_faceviews_AM_data_csv/raster_data_lupo_am_site221.csv  -->  2312 trials\n",
      "Freiwald_Tsao_faceviews_AM_data_csv/raster_data_lupo_am_site223.csv  -->  2312 trials\n",
      "\n",
      "Selected file with highest number of trials:\n",
      "Freiwald_Tsao_faceviews_AM_data_csv/raster_data_bert_am_site185.csv\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# Find the neuron file with the maximum number of trials\n",
    "# ------------------------------------------------\n",
    "\n",
    "trial_counts = {}\n",
    "\n",
    "# Count number of rows (trials) for each file\n",
    "for f in csv_files:\n",
    "    df_temp = pd.read_csv(f, nrows=5)     # read only 5 rows to get columns\n",
    "    full_df = pd.read_csv(f)              # load full file to get shape\n",
    "    trial_counts[f] = full_df.shape[0]    # number of rows = trials\n",
    "\n",
    "# Convert to sorted list (descending by number of trials)\n",
    "sorted_trials = sorted(trial_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top 5 files with the most trials:\")\n",
    "for f, count in sorted_trials[:5]:\n",
    "    print(f\"{f}  -->  {count} trials\")\n",
    "\n",
    "# Choose the file with maximum trials\n",
    "best_file = sorted_trials[0][0]\n",
    "\n",
    "print(\"\\nSelected file with highest number of trials:\")\n",
    "print(best_file)\n",
    "\n",
    "# Load this file as the example_file for Cell 2+\n",
    "example_file = pd.read_csv(best_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting: Freiwald_Tsao_faceviews_AM_data_csv/raster_data_bert_am_site185.csv\n",
      "Shape (rows = trials, columns = labels + time bins): (2685, 806)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_info.monkey</th>\n",
       "      <th>site_info.region</th>\n",
       "      <th>labels.stimID</th>\n",
       "      <th>labels.person</th>\n",
       "      <th>labels.orientation</th>\n",
       "      <th>labels.orient_person_combo</th>\n",
       "      <th>time.1_2</th>\n",
       "      <th>time.2_3</th>\n",
       "      <th>time.3_4</th>\n",
       "      <th>time.4_5</th>\n",
       "      <th>...</th>\n",
       "      <th>time.791_792</th>\n",
       "      <th>time.792_793</th>\n",
       "      <th>time.793_794</th>\n",
       "      <th>time.794_795</th>\n",
       "      <th>time.795_796</th>\n",
       "      <th>time.796_797</th>\n",
       "      <th>time.797_798</th>\n",
       "      <th>time.798_799</th>\n",
       "      <th>time.799_800</th>\n",
       "      <th>time.800_801</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert</td>\n",
       "      <td>am</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>front</td>\n",
       "      <td>front 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert</td>\n",
       "      <td>am</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>front</td>\n",
       "      <td>front 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert</td>\n",
       "      <td>am</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>front</td>\n",
       "      <td>front 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert</td>\n",
       "      <td>am</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>front</td>\n",
       "      <td>front 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bert</td>\n",
       "      <td>am</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>front</td>\n",
       "      <td>front 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 806 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  site_info.monkey site_info.region  labels.stimID  labels.person  \\\n",
       "0             bert               am              1              1   \n",
       "1             bert               am              1              1   \n",
       "2             bert               am              1              1   \n",
       "3             bert               am              1              1   \n",
       "4             bert               am              1              1   \n",
       "\n",
       "  labels.orientation labels.orient_person_combo  time.1_2  time.2_3  time.3_4  \\\n",
       "0              front                    front 1         0         0         0   \n",
       "1              front                    front 1         0         0         0   \n",
       "2              front                    front 1         0         0         0   \n",
       "3              front                    front 1         0         0         0   \n",
       "4              front                    front 1         0         0         0   \n",
       "\n",
       "   time.4_5  ...  time.791_792  time.792_793  time.793_794  time.794_795  \\\n",
       "0         0  ...             0             0             0             0   \n",
       "1         0  ...             0             0             0             0   \n",
       "2         0  ...             0             0             0             0   \n",
       "3         0  ...             0             0             0             0   \n",
       "4         0  ...             0             0             0             0   \n",
       "\n",
       "   time.795_796  time.796_797  time.797_798  time.798_799  time.799_800  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   time.800_801  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 806 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of label columns: 6\n",
      "Label columns: ['site_info.monkey', 'site_info.region', 'labels.stimID', 'labels.person', 'labels.orientation', 'labels.orient_person_combo']\n",
      "\n",
      "Number of time-bin columns: 800\n",
      "First 5 time columns: ['time.1_2', 'time.2_3', 'time.3_4', 'time.4_5', 'time.5_6']\n",
      "Last 5 time columns: ['time.796_797', 'time.797_798', 'time.798_799', 'time.799_800', 'time.800_801']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# Inspect the first neuron file\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Load the first neuron file\n",
    "example_file = pd.read_csv(best_file)\n",
    "\n",
    "print(\"Inspecting:\", best_file)\n",
    "print(\"Shape (rows = trials, columns = labels + time bins):\", example_file.shape)\n",
    "\n",
    "# Show first 5 rows\n",
    "display(example_file.head())\n",
    "\n",
    "# Identify label columns\n",
    "label_cols = [c for c in example_file.columns \n",
    "              if c.startswith(\"site_info\") or c.startswith(\"labels\")]\n",
    "\n",
    "# Identify time-bin columns (these hold neural spikes)\n",
    "time_cols = [c for c in example_file.columns if c.startswith(\"time\")]\n",
    "\n",
    "print(\"\\nNumber of label columns:\", len(label_cols))\n",
    "print(\"Label columns:\", label_cols)\n",
    "\n",
    "print(\"\\nNumber of time-bin columns:\", len(time_cols))\n",
    "print(\"First 5 time columns:\", time_cols[:5])\n",
    "print(\"Last 5 time columns:\", time_cols[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity labels shape: (2685,)\n",
      "Orientation labels (string) shape: (2685,)\n",
      "Orientation labels (coded) shape: (2685,)\n",
      "\n",
      "Unique identities present: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25]\n",
      "Number of unique identities: 25\n",
      "\n",
      "Unique orientations (string): Index(['back', 'down', 'front', 'left 3/4', 'left profile', 'right 3/4',\n",
      "       'right profile', 'up'],\n",
      "      dtype='object')\n",
      "Number of unique orientations: 8\n",
      "\n",
      "Orientation code mapping:\n",
      "  0 -> back\n",
      "  1 -> down\n",
      "  2 -> front\n",
      "  3 -> left 3/4\n",
      "  4 -> left profile\n",
      "  5 -> right 3/4\n",
      "  6 -> right profile\n",
      "  7 -> up\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# Extract labels for this neuron\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Identity labels\n",
    "y_identity = example_file[\"labels.person\"].values\n",
    "\n",
    "# Orientation labels \n",
    "y_orientation_str = example_file[\"labels.orientation\"].values\n",
    "\n",
    "# Convert orientation strings to integer category codes\n",
    "orientation_categories = pd.Categorical(y_orientation_str)\n",
    "y_orientation = orientation_categories.codes  # integer encoding\n",
    "\n",
    "# Print shapes\n",
    "print(\"Identity labels shape:\", y_identity.shape)\n",
    "print(\"Orientation labels (string) shape:\", y_orientation_str.shape)\n",
    "print(\"Orientation labels (coded) shape:\", y_orientation.shape)\n",
    "\n",
    "# Unique identity values\n",
    "print(\"\\nUnique identities present:\", np.unique(y_identity))\n",
    "print(\"Number of unique identities:\", len(np.unique(y_identity)))\n",
    "\n",
    "# Unique orientations\n",
    "print(\"\\nUnique orientations (string):\", orientation_categories.categories)\n",
    "print(\"Number of unique orientations:\", len(orientation_categories.categories))\n",
    "\n",
    "# Orientation code -> label mapping\n",
    "print(\"\\nOrientation code mapping:\")\n",
    "for code, label in enumerate(orientation_categories.categories):\n",
    "    print(f\"  {code} -> {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of time bins used: 200\n",
      "First 5 selected time bins: ['time.1_2', 'time.2_3', 'time.3_4', 'time.4_5', 'time.5_6']\n",
      "Last 5 selected time bins: ['time.196_197', 'time.197_198', 'time.198_199', 'time.199_200', 'time.200_201']\n",
      "\n",
      "Feature vector X_neuron shape: (2685,)\n",
      "First 10 spike counts: [4 6 7 5 4 6 5 6 6 5]\n",
      "Min/Max spike count: 0 9\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# Extract spike-count features for this neuron\n",
    "# ------------------------------------------------\n",
    "\n",
    "# first 200 ms of data\n",
    "time_cols_0_200 = time_cols[:200]\n",
    "\n",
    "print(\"Number of time bins used:\", len(time_cols_0_200))\n",
    "print(\"First 5 selected time bins:\", time_cols_0_200[:5])\n",
    "print(\"Last 5 selected time bins:\", time_cols_0_200[-5:])\n",
    "\n",
    "# Compute spike counts per trial\n",
    "X_neuron = example_file[time_cols_0_200].sum(axis=1).values\n",
    "\n",
    "print(\"\\nFeature vector X_neuron shape:\", X_neuron.shape)\n",
    "print(\"First 10 spike counts:\", X_neuron[:10])\n",
    "print(\"Min/Max spike count:\", X_neuron.min(), X_neuron.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2685, 1)\n",
      "y_identity shape: (2685,)\n",
      "y_orientation shape: (2685,)\n",
      "\n",
      "First 10 rows of X:\n",
      "[[4]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [4]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# Reshape feature vector to 2D matrix\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Reshape into (n_samples, n_features)\n",
    "X = X_neuron.reshape(-1, 1)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y_identity shape:\", y_identity.shape)\n",
    "print(\"y_orientation shape:\", y_orientation.shape)\n",
    "\n",
    "# preview\n",
    "print(\"\\nFirst 10 rows of X:\")\n",
    "print(X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models for classification _(if applicable)_\n",
    "_(What models will you be using for classification? Why did you choose to use them? What questions would you answer with them? How would you evaluate if each model? What cross-validation method did you use?)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may add some code here to show how the model works in principle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models for regression _(if applicable)_\n",
    "_(What models will you be using for regression? Why did you choose to use them? What questions would you answer with them? How would you evaluate if each model? What cross-validation method did you use?)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may add some code here to show how the model works in principle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other methods used _(if applicable)_\n",
    "\n",
    "_(If this is a preprocessing step to prepare your data for regression or classification models, you should put this subsection before your explanation for the regression or classification models.)_\n",
    "\n",
    "_(What method did you use otherwise? Why did you choose to use them? What questions would you answer with them? How would you evaluate the results? What cross-validation method did you use when applicable?)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may add some code here to show how the method works in principle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# you may add some code here to show how the model works in principle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(What did you find when you carried out your methods? Some of your code related to\n",
    "presenting results/figures/data may be replicated from the methods section or may only be present in\n",
    "this section. All of the plots that you plan on using for your presentation should be present in this\n",
    "section)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification results\n",
    "_(What are you trying to do here?)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did you do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(How do you interpret what you see?)_\n",
    "\n",
    "_(What are you doing next?)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did you do it (etc. etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression results\n",
    "_(What are you trying to do here?)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did you do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(How do you interpret what you see?)_\n",
    "\n",
    "_(What are you doing next?)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did you do it (etc. etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other results\n",
    "_(What are you trying to do here?)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did you do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(How do you interpret what you see?)_\n",
    "\n",
    "_(What are you doing next?)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did you do it (etc. etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(What did you learn from your results? What obstacles did you run into? What would you do differently next time? Clearly provide quantitative answers to your question(s)?  At least one of your questions should be answered with numbers.  That is, it is not sufficient to answer \"yes\" or \"no\", but rather to say something quantitative such as variable 1 increased roughly 10% for every 1 year increase in variable 2.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discussion on the classification results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discussion on the regression results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discussion on the other results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion and future steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author contribution\n",
    "\n",
    "_(Please describe the contribution of each member of group)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(List the source(s) for any data and/or literature cited in your project.  Ideally, this should be formatted using a formal citation format (MLA or APA or other, your choice!).   Multiple free online citation generators are available such as <a href=\"http://www.easybib.com/style\">http://www.easybib.com/style</a>. **Important:** if you use **any** code that you find on the internet for your project you **must** cite it or you risk losing most/all of the points for you project.)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
